---type-get_config- <class 'function'>
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10 entries, 0 to 9
Data columns (total 12 columns):
 #   Column               Non-Null Count  Dtype  
---  ------               --------------  -----  
 0   Unnamed: 0           10 non-null     int64  
 1   ls_bbox_area         10 non-null     float64
 2   ls_other_id          10 non-null     int64  
 3   image_INT_id         10 non-null     int64  
 4   category_id          10 non-null     int64  
 5   X_TOP_LEFT_x1        10 non-null     float64
 6   ls_x2                10 non-null     float64
 7   ls_y1                10 non-null     float64
 8   Y_BOTTOM_RIGHT_y2    10 non-null     float64
 9   coco_remote_url      10 non-null     object 
 10  image_jpg_file_name  10 non-null     object 
 11  image_local_path     10 non-null     object 
dtypes: float64(5), int64(4), object(3)
memory usage: 1.1+ KB
--[INFO-get_std_data_dict]--df_annos_coco_chunks.info()- None
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 28.670000000000016
--[INFO]----bbox_width-- 38.650000000000034
--[INFO]----bbox_xcenter,---ycenter- 19.325000000000017 14.335000000000008
--[INFO]----yolo_height-- 0.04479687500000003
--[INFO]----float_x_center,float_y_center-- 10222.925000000008 9174.400000000005
--[INFO]---float_width--,--float_height- 38.650000000000034 28.670000000000016
--[INFO]---min_x,min_y- 473.07 395.93
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_1_18', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_1_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 177.35999999999999
--[INFO]----bbox_width-- 60.84000000000003
--[INFO]----bbox_xcenter,---ycenter- 30.420000000000016 88.67999999999999
--[INFO]----yolo_height-- 0.27712499999999995
--[INFO]----float_x_center,float_y_center-- 16092.180000000008 56755.2
--[INFO]---float_width--,--float_height- 60.84000000000003 177.35999999999996
--[INFO]---min_x,min_y- 204.01 235.08
--[INFO]---bbox_gt_label-- 1
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'annotations': [{'id': 2, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'bbox': (204.01, 235.08, 60.0, 177.0), 'bbox_mode': 1, 'area': 10620, 'category_id': '1'}]}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 106.44999999999999
--[INFO]----bbox_width-- 339.79
--[INFO]----bbox_xcenter,---ycenter- 169.895 53.224999999999994
--[INFO]----yolo_height-- 0.166328125
--[INFO]----float_x_center,float_y_center-- 89874.455 34064.0
--[INFO]---float_width--,--float_height- 339.79 106.44999999999999
--[INFO]---min_x,min_y- 0.43 499.79
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_3_15', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_3_15', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 152.76
--[INFO]----bbox_width-- 52.51000000000002
--[INFO]----bbox_xcenter,---ycenter- 26.25500000000001 76.38
--[INFO]----yolo_height-- 0.2386875
--[INFO]----float_x_center,float_y_center-- 13888.895000000006 48883.2
--[INFO]---float_width--,--float_height- 52.51000000000002 152.76
--[INFO]---min_x,min_y- 204.42 304.1
--[INFO]---bbox_gt_label-- 2
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'annotations': [{'id': 3, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'bbox': (204.42, 304.1, 52.0, 152.0), 'bbox_mode': 1, 'area': 7904, 'category_id': '2'}]}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 279.77
--[INFO]----bbox_width-- 151.96999999999997
--[INFO]----bbox_xcenter,---ycenter- 75.98499999999999 139.885
--[INFO]----yolo_height-- 0.5828541666666667
--[INFO]----float_x_center,float_y_center-- 48630.399999999994 67144.79999999999
--[INFO]---float_width--,--float_height- 151.96999999999997 279.77
--[INFO]---min_x,min_y- 272.1 200.23
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_5_18', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_5_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 73.53
--[INFO]----bbox_width-- 27.439999999999998
--[INFO]----bbox_xcenter,---ycenter- 13.719999999999999 36.765
--[INFO]----yolo_height-- 0.1531875
--[INFO]----float_x_center,float_y_center-- 8780.8 17647.2
--[INFO]---float_width--,--float_height- 27.439999999999998 73.53
--[INFO]---min_x,min_y- 181.23 86.28
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_6_44', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_6_44', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 220.79
--[INFO]----bbox_width-- 261.03999999999996
--[INFO]----bbox_xcenter,---ycenter- 130.51999999999998 110.395
--[INFO]----yolo_height-- 0.45997916666666666
--[INFO]----float_x_center,float_y_center-- 83532.79999999999 52989.6
--[INFO]---float_width--,--float_height- 261.03999999999996 220.79
--[INFO]---min_x,min_y- 174.74 0.0
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_7_70', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_7_70', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 356.81
--[INFO]----bbox_width-- 372.85
--[INFO]----bbox_xcenter,---ycenter- 186.425 178.405
--[INFO]----yolo_height-- 0.5830228758169934
--[INFO]----float_x_center,float_y_center-- 114092.1 109183.86
--[INFO]---float_width--,--float_height- 372.85 356.80999999999995
--[INFO]---min_x,min_y- 124.71 196.18
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_8_18', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_8_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 390.96000000000004
--[INFO]----bbox_width-- 501.48
--[INFO]----bbox_xcenter,---ycenter- 250.74 195.48000000000002
--[INFO]----yolo_height-- 0.6388235294117648
--[INFO]----float_x_center,float_y_center-- 153452.88 119633.76000000001
--[INFO]---float_width--,--float_height- 501.48 390.96000000000004
--[INFO]---min_x,min_y- 59.4 50.77
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_9_4', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_9_4', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 26.74000000000001
--[INFO]----bbox_width-- 27.52000000000004
--[INFO]----bbox_xcenter,---ycenter- 13.76000000000002 13.370000000000005
--[INFO]----yolo_height-- 0.04369281045751636
--[INFO]----float_x_center,float_y_center-- 8421.120000000012 8182.440000000002
--[INFO]---float_width--,--float_height- 27.52000000000004 26.74000000000001
--[INFO]---min_x,min_y- 288.83 70.02
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_10_47', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_10_47', 'annotations': []}
---[INFO-coco_std_data_dict]--len(ls_dataset_dicts---
 10
--[INFO-register_data]-coco_std_data_dict_Registered-- 10
--[INFO_register_data]-BEFORE_SET>> thing_classes-- Metadata(name='coco_eval_data_1')
--[INFO_register_data]---MetadataCatalog___len_Classes: 4
--[INFO_register_data]---MetadataCatalog___NAME_Classes: ['person', 'bicycle', 'car', 'motorcycle']
--[INFO_register_data]-NOW_SET>> thing_classes-- Metadata(name='coco_eval_data_1', thing_classes=['person', 'bicycle', 'car', 'motorcycle'])
loading annotations into memory...
Done (t=0.34s)
creating index...
index created!
----COCO_CLASS--ID , for the COCO_CLASS_NAME--->>  1 __ person
----COCO_CLASS--ID , for the COCO_CLASS_NAME--->>  2 __ bicycle
----COCO_CLASS--ID , for the COCO_CLASS_NAME--->>  3 __ car
----COCO_CLASS--ID , for the COCO_CLASS_NAME--->>  4 __ motorcycle
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10 entries, 0 to 9
Data columns (total 12 columns):
 #   Column               Non-Null Count  Dtype  
---  ------               --------------  -----  
 0   Unnamed: 0           10 non-null     int64  
 1   ls_bbox_area         10 non-null     float64
 2   ls_other_id          10 non-null     int64  
 3   image_INT_id         10 non-null     int64  
 4   category_id          10 non-null     int64  
 5   X_TOP_LEFT_x1        10 non-null     float64
 6   ls_x2                10 non-null     float64
 7   ls_y1                10 non-null     float64
 8   Y_BOTTOM_RIGHT_y2    10 non-null     float64
 9   coco_remote_url      10 non-null     object 
 10  image_jpg_file_name  10 non-null     object 
 11  image_local_path     10 non-null     object 
dtypes: float64(5), int64(4), object(3)
memory usage: 1.1+ KB
--[INFO-get_std_data_dict]--df_annos_coco_chunks.info()- None
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 28.670000000000016
--[INFO]----bbox_width-- 38.650000000000034
--[INFO]----bbox_xcenter,---ycenter- 19.325000000000017 14.335000000000008
--[INFO]----yolo_height-- 0.04479687500000003
--[INFO]----float_x_center,float_y_center-- 10222.925000000008 9174.400000000005
--[INFO]---float_width--,--float_height- 38.650000000000034 28.670000000000016
--[INFO]---min_x,min_y- 473.07 395.93
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_1_18', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_1_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 177.35999999999999
--[INFO]----bbox_width-- 60.84000000000003
--[INFO]----bbox_xcenter,---ycenter- 30.420000000000016 88.67999999999999
--[INFO]----yolo_height-- 0.27712499999999995
--[INFO]----float_x_center,float_y_center-- 16092.180000000008 56755.2
--[INFO]---float_width--,--float_height- 60.84000000000003 177.35999999999996
--[INFO]---min_x,min_y- 204.01 235.08
--[INFO]---bbox_gt_label-- 1
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'annotations': [{'id': 2, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'bbox': (204.01, 235.08, 60.0, 177.0), 'bbox_mode': 1, 'area': 10620, 'category_id': '1'}]}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 106.44999999999999
--[INFO]----bbox_width-- 339.79
--[INFO]----bbox_xcenter,---ycenter- 169.895 53.224999999999994
--[INFO]----yolo_height-- 0.166328125
--[INFO]----float_x_center,float_y_center-- 89874.455 34064.0
--[INFO]---float_width--,--float_height- 339.79 106.44999999999999
--[INFO]---min_x,min_y- 0.43 499.79
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_3_15', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_3_15', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 152.76
--[INFO]----bbox_width-- 52.51000000000002
--[INFO]----bbox_xcenter,---ycenter- 26.25500000000001 76.38
--[INFO]----yolo_height-- 0.2386875
--[INFO]----float_x_center,float_y_center-- 13888.895000000006 48883.2
--[INFO]---float_width--,--float_height- 52.51000000000002 152.76
--[INFO]---min_x,min_y- 204.42 304.1
--[INFO]---bbox_gt_label-- 2
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'annotations': [{'id': 3, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'bbox': (204.42, 304.1, 52.0, 152.0), 'bbox_mode': 1, 'area': 7904, 'category_id': '2'}]}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 279.77
--[INFO]----bbox_width-- 151.96999999999997
--[INFO]----bbox_xcenter,---ycenter- 75.98499999999999 139.885
--[INFO]----yolo_height-- 0.5828541666666667
--[INFO]----float_x_center,float_y_center-- 48630.399999999994 67144.79999999999
--[INFO]---float_width--,--float_height- 151.96999999999997 279.77
--[INFO]---min_x,min_y- 272.1 200.23
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_5_18', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_5_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 73.53
--[INFO]----bbox_width-- 27.439999999999998
--[INFO]----bbox_xcenter,---ycenter- 13.719999999999999 36.765
--[INFO]----yolo_height-- 0.1531875
--[INFO]----float_x_center,float_y_center-- 8780.8 17647.2
--[INFO]---float_width--,--float_height- 27.439999999999998 73.53
--[INFO]---min_x,min_y- 181.23 86.28
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_6_44', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_6_44', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 220.79
--[INFO]----bbox_width-- 261.03999999999996
--[INFO]----bbox_xcenter,---ycenter- 130.51999999999998 110.395
--[INFO]----yolo_height-- 0.45997916666666666
--[INFO]----float_x_center,float_y_center-- 83532.79999999999 52989.6
--[INFO]---float_width--,--float_height- 261.03999999999996 220.79
--[INFO]---min_x,min_y- 174.74 0.0
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_7_70', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_7_70', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 356.81
--[INFO]----bbox_width-- 372.85
--[INFO]----bbox_xcenter,---ycenter- 186.425 178.405
--[INFO]----yolo_height-- 0.5830228758169934
--[INFO]----float_x_center,float_y_center-- 114092.1 109183.86
--[INFO]---float_width--,--float_height- 372.85 356.80999999999995
--[INFO]---min_x,min_y- 124.71 196.18
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_8_18', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_8_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 390.96000000000004
--[INFO]----bbox_width-- 501.48
--[INFO]----bbox_xcenter,---ycenter- 250.74 195.48000000000002
--[INFO]----yolo_height-- 0.6388235294117648
--[INFO]----float_x_center,float_y_center-- 153452.88 119633.76000000001
--[INFO]---float_width--,--float_height- 501.48 390.96000000000004
--[INFO]---min_x,min_y- 59.4 50.77
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_9_4', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_9_4', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 26.74000000000001
--[INFO]----bbox_width-- 27.52000000000004
--[INFO]----bbox_xcenter,---ycenter- 13.76000000000002 13.370000000000005
--[INFO]----yolo_height-- 0.04369281045751636
--[INFO]----float_x_center,float_y_center-- 8421.120000000012 8182.440000000002
--[INFO]---float_width--,--float_height- 27.52000000000004 26.74000000000001
--[INFO]---min_x,min_y- 288.83 70.02
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_10_47', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_10_47', 'annotations': []}
---[INFO-coco_std_data_dict]--len(ls_dataset_dicts---
 10
--[INFO-train_data_custom]-coco_std_data_dict_Registered-- 10
--[INFO-train_data_custom]---MetadataCatalog___len_Classes: 4
--[INFO-train_data_custom]---MetadataCatalog__names_of COCO Classes: ['person', 'bicycle', 'car', 'motorcycle']
--[INFO-train_data_custom]--NOW_SET>> thing_classes---: Metadata(name='coco_eval_data_2', thing_classes=['person', 'bicycle', 'car', 'motorcycle'])
[INFO-train_data_custom]--args_default_init---: <class 'argparse.Namespace'>
[INFO-train_data_custom]--args_default_init--1-: Namespace(config_file='', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[INFO-train_data_custom]--args_default_init--2: Namespace(config_file='', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
--[INFO-setup]--args.opts-- []
--[INFO-setup]--setup(custom_dataset_name,args-----
 CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ()
  TRAIN: ()
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (800,)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
    USE_FED_LOSS: False
    USE_SIGMOID_CE: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    CONV_DIMS: [-1]
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: 
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: False
  BASE_LR: 0.001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 16
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 40000
  MOMENTUM: 0.9
  NESTEROV: False
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: False
  STEPS: (30000,)
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: None
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
--[INFO-setup]--detect2_output_dir---
 ./output_dir/
--[INFO-setup]--CONFIG going to build_model(cfg)__
 CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 2
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ()
  TRAIN: ('coco_eval_data_2',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
    USE_FED_LOSS: False
    USE_SIGMOID_CE: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 4
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.7
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    CONV_DIMS: [-1]
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
OUTPUT_DIR: ./output_dir/
SEED: -1
SOLVER:
  AMP:
    ENABLED: False
  BASE_LR: 0.00025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2000
  MOMENTUM: 0.9
  NESTEROV: False
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: False
  STEPS: []
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: None
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[32m[11/01 03:12:02 detectron2]: [0mRank of current process: 0. World size: 1
[32m[11/01 03:12:03 detectron2]: [0mEnvironment info:
----------------------  --------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.9.13 (main, Oct 13 2022, 21:15:33) [GCC 11.2.0]
numpy                   1.23.3
detectron2              0.6 @/home/dhankar/temp/11_22/det2/detectron2/detectron2
Compiler                GCC 7.5
CUDA compiler           CUDA 11.0
detectron2 arch flags   7.5
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.10.1 @/home/dhankar/anaconda3/envs/env2_det2/lib/python3.9/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   GeForce GTX 1650 (arch=7.5)
Driver version          450.51.05
CUDA_HOME               /usr/local/cuda-11.0
Pillow                  8.3.2
torchvision             0.11.2 @/home/dhankar/anaconda3/envs/env2_det2/lib/python3.9/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5
iopath                  0.1.9
cv2                     4.6.0
----------------------  --------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

[32m[11/01 03:12:03 detectron2]: [0mCommand line arguments: Namespace(config_file='', resume=False, eval_only=False, num_gpus=1, num_machines=1, machine_rank=0, dist_url='tcp://127.0.0.1:50152', opts=[])
[32m[11/01 03:12:03 detectron2]: [0mRunning with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39mcoco_eval_data_2
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.9
[38;5;15m    [39m-[38;5;15m [39m0.9
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mrelative_range
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mBGR
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mpolygon
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m1333
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m1333
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m800
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m640
[38;5;15m  [39m-[38;5;15m [39m672
[38;5;15m  [39m-[38;5;15m [39m704
[38;5;15m  [39m-[38;5;15m [39m736
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m800
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m64
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m128
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mbuild_resnet_fpn_backbone
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mGeneralizedRCNN
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m1.0
[38;5;15m  [39m-[38;5;15m [39m1.0
[38;5;15m  [39m-[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m-[38;5;15m [39mres3
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m-[38;5;15m [39mres5
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mFastRCNNConvFCHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m7
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp2
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mStandardROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp2
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp2
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mSemSegFPNHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m54
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39mhttps://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./output_dir/
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.00025
[38;5;15m  [39m[38;5;197mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mvalue
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupMultiStepLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m3
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m0.001
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.0001
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4000
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m400
[38;5;15m    [39m-[38;5;15m [39m500
[38;5;15m    [39m-[38;5;15m [39m600
[38;5;15m    [39m-[38;5;15m [39m700
[38;5;15m    [39m-[38;5;15m [39m800
[38;5;15m    [39m-[38;5;15m [39m900
[38;5;15m    [39m-[38;5;15m [39m1000
[38;5;15m    [39m-[38;5;15m [39m1100
[38;5;15m    [39m-[38;5;15m [39m1200
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[32m[11/01 03:12:03 detectron2]: [0mFull config saved to ./output_dir/config.yaml
[32m[11/01 03:12:03 d2.utils.env]: [0mUsing a generated random seed 3369084
--[INFO-train_data_custom]--type(model
 <class 'detectron2.modeling.meta_arch.rcnn.GeneralizedRCNN'>
--[INFO-train_data_custom]---SUMMARY__model
 GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=5, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)
    )
  )
)
--[INFO-Cls:train_coco_data--Meth:do_train]--INIT--CONFIG-- CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 2
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ()
  TRAIN: ('coco_eval_data_2',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1333
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 800
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32], [64], [128], [256], [512]]
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_fpn_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res2', 'res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NORM: 
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: FastRCNNConvFCHead
    NORM: 
    NUM_CONV: 0
    NUM_FC: 2
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
    USE_FED_LOSS: False
    USE_SIGMOID_CE: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 256
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: StandardROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 4
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.7
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 4
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    CONV_DIMS: [-1]
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5', 'p6']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 1000
    PRE_NMS_TOPK_TEST: 1000
    PRE_NMS_TOPK_TRAIN: 2000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl
OUTPUT_DIR: ./output_dir/
SEED: -1
SOLVER:
  AMP:
    ENABLED: False
  BASE_LR: 0.00025
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 2000
  MOMENTUM: 0.9
  NESTEROV: False
  NUM_DECAYS: 3
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: False
  STEPS: []
  WARMUP_FACTOR: 0.001
  WARMUP_ITERS: 1000
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: None
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
--[INFO-Cls:train_coco_data--Meth:do_train]---SUMMARY--model- GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=5, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)
    )
  )
)
[32m[11/01 03:12:03 fvcore.common.checkpoint]: [0m[Checkpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl ...
[32m[11/01 03:12:03 fvcore.common.checkpoint]: [0mReading a file from 'Detectron2 Model Zoo'
[5m[31mWARNING[0m [32m[11/01 03:12:03 fvcore.common.checkpoint]: [0mSkip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.
[5m[31mWARNING[0m [32m[11/01 03:12:03 fvcore.common.checkpoint]: [0mSkip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.
[5m[31mWARNING[0m [32m[11/01 03:12:03 fvcore.common.checkpoint]: [0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.
[5m[31mWARNING[0m [32m[11/01 03:12:03 fvcore.common.checkpoint]: [0mSkip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.
[5m[31mWARNING[0m [32m[11/01 03:12:03 fvcore.common.checkpoint]: [0mSome model parameters or buffers are not found in the checkpoint:
[34mroi_heads.box_predictor.bbox_pred.{bias, weight}[0m
[34mroi_heads.box_predictor.cls_score.{bias, weight}[0m
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10 entries, 0 to 9
Data columns (total 12 columns):
 #   Column               Non-Null Count  Dtype  
---  ------               --------------  -----  
 0   Unnamed: 0           10 non-null     int64  
 1   ls_bbox_area         10 non-null     float64
 2   ls_other_id          10 non-null     int64  
 3   image_INT_id         10 non-null     int64  
 4   category_id          10 non-null     int64  
 5   X_TOP_LEFT_x1        10 non-null     float64
 6   ls_x2                10 non-null     float64
 7   ls_y1                10 non-null     float64
 8   Y_BOTTOM_RIGHT_y2    10 non-null     float64
 9   coco_remote_url      10 non-null     object 
 10  image_jpg_file_name  10 non-null     object 
 11  image_local_path     10 non-null     object 
dtypes: float64(5), int64(4), object(3)
memory usage: 1.1+ KB
--[INFO-get_std_data_dict]--df_annos_coco_chunks.info()- None
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 28.670000000000016
--[INFO]----bbox_width-- 38.650000000000034
--[INFO]----bbox_xcenter,---ycenter- 19.325000000000017 14.335000000000008
--[INFO]----yolo_height-- 0.04479687500000003
--[INFO]----float_x_center,float_y_center-- 10222.925000000008 9174.400000000005
--[INFO]---float_width--,--float_height- 38.650000000000034 28.670000000000016
--[INFO]---min_x,min_y- 473.07 395.93
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_1_18', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_1_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 177.35999999999999
--[INFO]----bbox_width-- 60.84000000000003
--[INFO]----bbox_xcenter,---ycenter- 30.420000000000016 88.67999999999999
--[INFO]----yolo_height-- 0.27712499999999995
--[INFO]----float_x_center,float_y_center-- 16092.180000000008 56755.2
--[INFO]---float_width--,--float_height- 60.84000000000003 177.35999999999996
--[INFO]---min_x,min_y- 204.01 235.08
--[INFO]---bbox_gt_label-- 1
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'annotations': [{'id': 2, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_2_1', 'bbox': (204.01, 235.08, 60.0, 177.0), 'bbox_mode': 1, 'area': 10620, 'category_id': '1'}]}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 106.44999999999999
--[INFO]----bbox_width-- 339.79
--[INFO]----bbox_xcenter,---ycenter- 169.895 53.224999999999994
--[INFO]----yolo_height-- 0.166328125
--[INFO]----float_x_center,float_y_center-- 89874.455 34064.0
--[INFO]---float_width--,--float_height- 339.79 106.44999999999999
--[INFO]---min_x,min_y- 0.43 499.79
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_3_15', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_3_15', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000289343.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000289343.jpg
-img_init.shape--- (640, 529, 3)
--[INFO]----bbox_height-- 152.76
--[INFO]----bbox_width-- 52.51000000000002
--[INFO]----bbox_xcenter,---ycenter- 26.25500000000001 76.38
--[INFO]----yolo_height-- 0.2386875
--[INFO]----float_x_center,float_y_center-- 13888.895000000006 48883.2
--[INFO]---float_width--,--float_height- 52.51000000000002 152.76
--[INFO]---min_x,min_y- 204.42 304.1
--[INFO]---bbox_gt_label-- 2
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000289343.jpg', 'height': 640, 'width': 529, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'categories': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'annotations': [{'id': 3, 'image_id': './coco_val_images_2017/val2017/000000289343.jpg_4_2', 'bbox': (204.42, 304.1, 52.0, 152.0), 'bbox_mode': 1, 'area': 7904, 'category_id': '2'}]}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 279.77
--[INFO]----bbox_width-- 151.96999999999997
--[INFO]----bbox_xcenter,---ycenter- 75.98499999999999 139.885
--[INFO]----yolo_height-- 0.5828541666666667
--[INFO]----float_x_center,float_y_center-- 48630.399999999994 67144.79999999999
--[INFO]---float_width--,--float_height- 151.96999999999997 279.77
--[INFO]---min_x,min_y- 272.1 200.23
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_5_18', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_5_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 73.53
--[INFO]----bbox_width-- 27.439999999999998
--[INFO]----bbox_xcenter,---ycenter- 13.719999999999999 36.765
--[INFO]----yolo_height-- 0.1531875
--[INFO]----float_x_center,float_y_center-- 8780.8 17647.2
--[INFO]---float_width--,--float_height- 27.439999999999998 73.53
--[INFO]---min_x,min_y- 181.23 86.28
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_6_44', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_6_44', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000061471.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000061471.jpg
-img_init.shape--- (480, 640, 3)
--[INFO]----bbox_height-- 220.79
--[INFO]----bbox_width-- 261.03999999999996
--[INFO]----bbox_xcenter,---ycenter- 130.51999999999998 110.395
--[INFO]----yolo_height-- 0.45997916666666666
--[INFO]----float_x_center,float_y_center-- 83532.79999999999 52989.6
--[INFO]---float_width--,--float_height- 261.03999999999996 220.79
--[INFO]---min_x,min_y- 174.74 0.0
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000061471.jpg', 'height': 480, 'width': 640, 'image_id': './coco_val_images_2017/val2017/000000061471.jpg_7_70', 'categories': './coco_val_images_2017/val2017/000000061471.jpg_7_70', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 356.81
--[INFO]----bbox_width-- 372.85
--[INFO]----bbox_xcenter,---ycenter- 186.425 178.405
--[INFO]----yolo_height-- 0.5830228758169934
--[INFO]----float_x_center,float_y_center-- 114092.1 109183.86
--[INFO]---float_width--,--float_height- 372.85 356.80999999999995
--[INFO]---min_x,min_y- 124.71 196.18
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_8_18', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_8_18', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 390.96000000000004
--[INFO]----bbox_width-- 501.48
--[INFO]----bbox_xcenter,---ycenter- 250.74 195.48000000000002
--[INFO]----yolo_height-- 0.6388235294117648
--[INFO]----float_x_center,float_y_center-- 153452.88 119633.76000000001
--[INFO]---float_width--,--float_height- 501.48 390.96000000000004
--[INFO]---min_x,min_y- 59.4 50.77
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_9_4', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_9_4', 'annotations': []}
-[INFO--get_std_data_dict]-coco_img_name->>
 000000472375.jpg
-[INFO--get_std_data_dict]-image_local_path->>
 ./coco_val_images_2017/val2017/000000472375.jpg
-img_init.shape--- (612, 612, 3)
--[INFO]----bbox_height-- 26.74000000000001
--[INFO]----bbox_width-- 27.52000000000004
--[INFO]----bbox_xcenter,---ycenter- 13.76000000000002 13.370000000000005
--[INFO]----yolo_height-- 0.04369281045751636
--[INFO]----float_x_center,float_y_center-- 8421.120000000012 8182.440000000002
--[INFO]---float_width--,--float_height- 27.52000000000004 26.74000000000001
--[INFO]---min_x,min_y- 288.83 70.02
-[INFO]---coco_std_data_dict--
 {'file_name': './coco_val_images_2017/val2017/000000472375.jpg', 'height': 612, 'width': 612, 'image_id': './coco_val_images_2017/val2017/000000472375.jpg_10_47', 'categories': './coco_val_images_2017/val2017/000000472375.jpg_10_47', 'annotations': []}
---[INFO-coco_std_data_dict]--len(ls_dataset_dicts---
 10
[32m[11/01 03:12:06 d2.data.build]: [0mRemoved 8 images with no usable annotations. 2 images left.
[32m[11/01 03:12:06 d2.data.build]: [0mDistribution of instances among all 4 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 0            |  bicycle   | 1            |    car     | 1            |
| motorcycle | 0            |            |              |            |              |
|   total    | 2            |            |              |            |              |[0m
[32m[11/01 03:12:06 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[11/01 03:12:06 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[11/01 03:12:06 d2.data.common]: [0mSerializing 2 elements to byte tensors and concatenating them all ...
[32m[11/01 03:12:06 d2.data.common]: [0mSerialized dataset takes 0.00 MiB
--[INFO-Cls:train_coco_data--Meth:do_train]--Type(data_loader---- <class 'detectron2.data.common.AspectRatioGroupedDataset'>
--[INFO-Cls:train_coco_data--Meth:do_train]-Starting training from iteration__ 0
--[INFO-Cls:train_coco_data--Meth:do_train]--len(data_from_loader- 4
--[INFO-Cls:train_coco_data--Meth:do_train]--data_from_loader--IMAGE Names in Batch- ./coco_val_images_2017/val2017/000000289343.jpg
--[INFO-Cls:train_coco_data--Meth:do_train]--data_from_loader--IMAGE Names in Batch- ./coco_val_images_2017/val2017/000000289343.jpg
--[INFO-Cls:train_coco_data--Meth:do_train]--data_from_loader--IMAGE Names in Batch- ./coco_val_images_2017/val2017/000000289343.jpg
--[INFO-Cls:train_coco_data--Meth:do_train]--data_from_loader--IMAGE Names in Batch- ./coco_val_images_2017/val2017/000000289343.jpg
-[INFO-Cls:train_coco_data--Meth:do_train]---iteration- 0
